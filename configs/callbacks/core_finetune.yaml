model_summary:
  _target_: pytorch_lightning.callbacks.RichModelSummary
  max_depth: -1

learning_rate_monitor:
  _target_: pytorch_lightning.callbacks.LearningRateMonitor

metric_logger:
  _target_: src.lightning.callbacks.metric_logger.MetricLogger
  mode: "finetune"
  num_classes: 2
  corewise_inv_threshold: 0.5
  corewise_metrics: False

progress_bar:
  _target_: pytorch_lightning.callbacks.TQDMProgressBar
  refresh_rate: 50

#logger_checkpoint:
#  _target_: src.lightning.callbacks.wandb_checkpoint.WandbLoggerCheckpoint

model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: val/finetune_auc # name of the logged metric which determines when model is improving
    mode: "max" # "max" means higher metric value is better, can be also "min"
    save_top_k: 1 # save k best models (determined by above metric)
    save_last: True # additionaly always save model from last epoch
    verbose: False
    dirpath: "checkpoints/"
    filename: "epoch_{epoch:03d}"
    auto_insert_metric_name: False


#test_as_val_loader:
#  _target_: src.lightning.callbacks.TestAsValLoader
